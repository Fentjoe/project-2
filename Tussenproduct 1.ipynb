{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4c0b62-b8b7-43bb-9b83-907597cc3105",
   "metadata": {},
   "source": [
    "# Tussenproduct 1 : Data schoonmaak\n",
    "## De Haagse Hogeschool\n",
    "## Toegepaste Wiskunde\n",
    "\n",
    "\n",
    "Groep 3  \n",
    "Fenne van Agthoven, Phealana Fiamingo, Araksan Hassan, Kika van Vliet  \n",
    "Datum: 22-3-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab3bb5-5bdb-49ca-ba94-414e2ffc4d80",
   "metadata": {},
   "source": [
    "### Functie voor het schoonmaken van de gegeven ingrediënten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8283a549-320d-4515-bb43-5add693ca393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Lees de dataframes in\n",
    "ingr_per_group = pd.read_csv('tabellen/ingr_per_group(1).csv')\n",
    "data_ingr = pd.read_csv('tabellen/data_ingr.csv')\n",
    "ingr_per_group['ingredient'] = ingr_per_group['ingredient'].str.lower() # Zet alle ingredientnamen om in kleine letters\n",
    "data_ingr['ingredient'] = data_ingr['ingredient'].str.lower()\n",
    "ingr_group3 = ingr_per_group[(ingr_per_group['group'] == 3)] # Selecteer alleen de ingrediënten die bij onze groep (3) horen\n",
    "onze = data_ingr[data_ingr['ingredient'].isin(ingr_group3['ingredient'])] # Filter in de dataset de ingrediënten die bij onze groep horen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c0be5e-80f5-47f7-97bf-14e7a2cdc909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#onze.unit.value_counts()\n",
    "#onze[onze.unit == 'liter'].ingredient.value_counts()\n",
    "\n",
    "alle_units = set(onze['unit']) # Een set van alle unieke eenheden uit de dataset\n",
    "\n",
    "# Een omrekentabel voor de verschillende eenheden naar gram\n",
    "convert_tabel = [\n",
    "    ['el', 10],\n",
    "    ['ml', 0.92], \n",
    "    ['tl', 2], \n",
    "    ['kg', 1000], \n",
    "    ['schaal', 380], \n",
    "    ['liter', 920],\n",
    "    ['zak', 1000],\n",
    "    ['struik', 900],\n",
    "    ['zakje', 950],\n",
    "    ['krop', 800],\n",
    "    ['bakje', 850],\n",
    "    ['plakje', 50],\n",
    "    ['bak', 700],\n",
    "    ['pakje', 90],\n",
    "    ['stukje', 80],\n",
    "    ['blik', 920],\n",
    "    ['blikje', 85],\n",
    "    ['bakjes', 870],\n",
    "    ['plak', 65],\n",
    "    ['cupje', 70],\n",
    "    ['stuk', 950],\n",
    "    ['stronk', 850],\n",
    "    ['sneetje', 55],\n",
    "    ['pak', 700],\n",
    "    ['plakken', 60],\n",
    "    ['zakjes', 960],\n",
    "    ['vel', 70],\n",
    "    ['flesje', 780],\n",
    "    ['friszoete stevige', 1020],\n",
    "    ['bol', 920],\n",
    "    ['friszure', 1000],\n",
    "    ['kruimige', 980],\n",
    "    ['potje', 850],\n",
    "    ['schaaltjes', 910],\n",
    "    ['grote', 900],\n",
    "    ['zakken', 1100],\n",
    "    ['doos', 1000],\n",
    "    ['x 750 g', 750],\n",
    "    ['friszoete', 1040],\n",
    "    ['x 4 plakken', 400]\n",
    "]\n",
    "\n",
    "convert_df = pd.DataFrame(convert_tabel, columns=['eenheid', 'keer']) # Maakt van de omrekentabel een dataframe\n",
    "df_onze = onze.merge(convert_df, how='left', left_on= 'unit', right_on='eenheid') # Voeg omrekentabel DataFrame samen met ons DataFRame\n",
    "df_onze.keer = df_onze.keer.fillna(1) # Vul de NaN waardes met 1\n",
    "df_onze.quantity = df_onze.quantity * df_onze.keer # Reken de hoeveelheden om naar gram\n",
    "df_onze.unit = 'g' # Verander de eenheid naar gram\n",
    "df_onze = df_onze.drop(columns=['eenheid','keer']) # Verwijder de onnodige kolommen\n",
    "\n",
    "data_ingr_res = data_ingr.merge(df_onze, how='left',on='Unnamed: 0')\n",
    "data_ingr_res['recipe'] = data_ingr_res['recipe_y'].fillna(data_ingr_res['recipe_x'])\n",
    "data_ingr_res['ingredient'] = data_ingr_res['ingredient_y'].fillna(data_ingr_res['ingredient_x'])\n",
    "data_ingr_res['quantity'] = data_ingr_res['quantity_y'].fillna(data_ingr_res['quantity_x'])\n",
    "data_ingr_res['unit'] = data_ingr_res['unit_y'].fillna(data_ingr_res['unit_x'])\n",
    "data_ingr_res.drop(columns=['recipe_x', 'recipe_y', 'ingredient_x', 'ingredient_y', 'quantity_x', 'quantity_y', 'unit_x', 'unit_y'], inplace=True)                              \n",
    "\n",
    "# Tel hoevaak elk ingredient voorkomt\n",
    "a = df_onze.ingredient.value_counts().reset_index().rename(columns={\"index\": \"value\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e128b774-cdb2-4707-8a9e-eaccd2c03a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tomaat_t = (\"tomaat\", set([word for word in df_onze[\"ingredient\"] if \"toma\" in word and \"blik\" not in word and \"puree\"]))\n",
    "parma_t = (\"parmezaanse kaas\", set([word for word in df_onze[\"ingredient\"] if \"parm\" in word and \"prosciutto\" not in word]))\n",
    "paprika_t = (\"paprika\", set([word for word in df_onze[\"ingredient\"] if \"paprika\" in word]))\n",
    "paturain_t = (\"paturain\", set([word for word in df_onze[\"ingredient\"] if \"paturain\" in word]))\n",
    "olijven_t = (\"olijven\", set([word for word in df_onze[\"ingredient\"] if \"olij\" in word and \"olie\" not in word]))\n",
    "olijfolie_t = (\"olijfolie\", set([word for word in df_onze[\"ingredient\"] if \"olijfolie\" in word]))\n",
    "oreo_t = (\"oreo\", set([word for word in df_onze[\"ingredient\"] if \"oreo\" in word]))\n",
    "aardappel_t = (\"aardappel\", set([word for word in df_onze[\"ingredient\"] if \"pommes primeur\" in word or \"eigenheimer\" in word or \"aardappelen\" in word]))\n",
    "a_schijfjes_t = (\"aardappelschijfjes\", set([word for word in df_onze[\"ingredient\"] if \"aardappelschijfjes\" in word]))\n",
    "a_partjes_t = (\"aardappelpartjes\", set([word for word in df_onze[\"ingredient\"] if \"aardappelpartjes\" in word]))\n",
    "a_puree_t = (\"aardappelpuree\", set([word for word in df_onze[\"ingredient\"] if \"aardappelpuree\" in word]))\n",
    "ciabatta_t = (\"ciabatta\", set([word for word in df_onze[\"ingredient\"] if \"ciaba\" in word]))\n",
    "arachide_t = (\"arachide\", set([word for word in df_onze[\"ingredient\"] if \"arachide\" in word]))\n",
    "framboos_t = (\"framboos\", set([word for word in df_onze[\"ingredient\"] if \"framboos\" in word]))\n",
    "sp_peper_t = (\"spaanse peper\", set([word for word in df_onze[\"ingredient\"] if \"spaanse peper\" in word]))\n",
    "mayo_t = (\"mayonaise\", set([word for word in df_onze[\"ingredient\"] if \"mayo\" in word]))\n",
    "appel_t = (\"appels\", set([word for word in df_onze[\"ingredient\"] if \"pink lady\" in word or \"royal gala\" in word or word == 'appel']))\n",
    "amandel_melk_t = (\"amandeldrink\", set([word for word in df_onze[\"ingredient\"] if \"amandel drink\" in word or \"amandelmelk\" in word]))\n",
    "amandel_koek_t = (\"amandelkoekjes\", set([word for word in df_onze[\"ingredient\"] if \"amandelkoekjes\" in word]))\n",
    "\n",
    "ingr_tuple_lijst = [tomaat_t, parma_t, paprika_t, paturain_t, olijven_t, olijfolie_t, oreo_t, ciabatta_t, framboos_t, sp_peper_t, \n",
    "                    mayo_t, aardappel_t, a_schijfjes_t, a_partjes_t, a_puree_t, appel_t, amandel_melk_t, amandel_koek_t]\n",
    "\n",
    "for x in df_onze[\"ingredient\"]:\n",
    "    for y in ingr_tuple_lijst:\n",
    "        if x in y[1]:\n",
    "            df_onze[\"ingredient\"].replace(x, y[0], inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643fe3a-34b5-416f-8a96-531831ba9a2f",
   "metadata": {},
   "source": [
    "### Overzicht van de uitgevoerde bewerkingen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d25b1-0bdd-4476-b6be-7d2984eb7ef6",
   "metadata": {},
   "source": [
    "### Reflectie op de kwaliteit van de schoongemaakte data\n",
    "\n",
    "Bij de functie voor het schoonmaken van de dataset liepen wij tegen wat moeilijkheden aan. Bij bepaalde eenheden (zoals liter) konden ingredienten daarin ook van gewicht verschillen (water en olie), dus we konden niet een accurate omrekening maken omdat per ingredient de massadichtheid verschilde. Wij hebben het meest voorkomende ingredient met die eenheid als standaard massadichtheid genomen. Zo hebben wij alle ingredienten met die eenheid om kunnen rekenen naar gram. Dit is helaas minder accuraat voor de overige ingredienten in die eenheid. \n",
    "\n",
    "Wij moesten algemene namen bedenken voor diverse ingredienten. Zo hebben wij bijvoorbeeld parmigiano reggiano omgezet naar parmezaanse kaas, en verschillende soorten aardappelen naar aardappels. Dit is een goede methode om ingredienten algemener te maken, maar misschien komt dit niet overeen met de benamingen van andere groepen die dit ook gedaan hebben, het is tenslotte subjectief. Het was veel werk om deze code te schrijven aangezien het veel specifiek en handmatig werk was. We hebben wel de code die de wijzigingen implementeerd zo kort mogelijk kunnen houden. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca41ac-0698-4281-a780-75e4d87d5e12",
   "metadata": {},
   "source": [
    "### Een data bestand met de voorkeur voor gerechten van elk groepslid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68db9ab8-9ea0-4b1b-9672-ba162e244a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 8 fields in line 4, saw 9\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recepten_per_groepslid \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtabellen/Recepten_kiezen_g12.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m recepten_per_groepslid\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 8 fields in line 4, saw 9\n"
     ]
    }
   ],
   "source": [
    "recepten_per_groepslid = pd.read_csv('tabellen/Recepten_kiezen_g12.csv')\n",
    "recepten_per_groepslid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089197b5-364a-49b3-a6d0-bde700679cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac7680-5175-4d3f-bf63-10a0b72d9832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
